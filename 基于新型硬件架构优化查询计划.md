
# 概述
随着机器主存不断增长，查询性能越来越受限于查询过程中的CPU开销。传统的基于迭代器形式的查询处理技术虽然非常简单和灵活，但是由于`缺少局部性`并且`频繁的指令预测失效`导致对其现在的CPU非常不友好。近几年提出的`面向批量处理`以及`矢量元组处理`等技术主要用于解决上述问题，但是这些技术通常只能面向特定的执行计划场景。
本文提出了一种新颖的编译策略：使用LLVM编译框架将查询翻译为`紧凑且高效的机器码`. 即有`良好的代码和数据局部性`以及具有和手写c++代码性能相媲美的`具有良好的分支预测能力`。我们将这些技术集成在HyPer主存数据库系统中并且证明了只需要花费适当的编译时间使其拥有非常卓越的性能。

# 介绍
大多数数据库系统将指定的查询翻译为一个代数表达式，通过执行代数表达式产生结果。执行代数表达式的传统方式是迭代器模式【8】，也称之为Volcano-style处理【4】：每个物理代数操作将输入转换为一个元组流并且通过调用next函数来对其进行迭代。
这是一种简单并有效的接口，并且允许任意操作进行简单组合，很明显这是一种面向IO场景的产物，那个时候CPU消耗相对而言几乎可以忽略： `首先，对于每一个简单的元组next函数都会调用，即使是中间或者最终的结果，比如，数以百万次`。 `其次，next通常是基于函数指针的虚函数实现，这种调用由于无法发挥现代CPU的分支预测能力相比传统的函数调用更加昂贵`。`第三，这种模型通常会导致很差的代码局部性以及复杂的临时记录开销`。这可以通过一个简单的压缩表扫描来证实。由于必须每次产生一个元组，表操作操作符需要记录当前元组的位置并且在需要下个元组时跳转到对应的解压缩代码地址。
这些问题导致一些现代的系统开始抛弃传统的迭代器模型，其或者再内部通过一次解压缩一批元组，或者再外部通过每次next迭代遍历更多的元组【11】，或者一次产生所有的元组【1】。这种面向块的处理其调用代价相对很低使得相对迭代大量元组而言减少了代价。但是也极大消除了迭代器模型的能力，比如不再具有pipeline数据的能力。Pipeline意味着一个操作对数据无需拷贝或者组装可以将数据传递给其父操作符。比如，selections是一个pipeling操作，并且仅仅对数据做传递。但是更复杂的操作比如join也可以pipelined，至少输入环节。当产生更多的元组时这种简单的pipelining将无法使用，元组只有通过materialization才可以继续呗访问。这种materialization也有一些优势，比如允许向量化操作【2】，但是通常丧失pipelining将会由于其需要消耗更多内存带宽显得不太值得。
本文的一个有趣的观察是：特定实现的程序甚至可以媲美非常高效的向量化系统（表1）。

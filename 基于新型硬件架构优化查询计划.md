
# 概述
随着机器主存不断增长，查询性能越来越受限于查询过程中的CPU开销。传统的基于迭代器形式的查询处理技术虽然非常简单和灵活，但是由于`缺少局部性`并且`频繁的指令预测失效`导致对其现在的CPU非常不友好。近几年提出的`面向批量处理`以及`矢量元组处理`等技术主要用于解决上述问题，但是这些技术通常只能面向特定的执行计划场景。
本文提出了一种新颖的编译策略：使用LLVM编译框架将查询翻译为`紧凑且高效的机器码`. 即有`良好的代码和数据局部性`以及具有和手写c++代码性能相媲美的`具有良好的分支预测能力`。我们将这些技术集成在HyPer主存数据库系统中并且证明了只需要花费适当的编译时间使其拥有非常卓越的性能。

# 介绍
大多数数据库系统将指定的查询翻译为一个代数表达式，通过执行代数表达式产生结果。执行代数表达式的传统方式是迭代器模式【8】，也称之为Volcano-style处理【4】：每个物理代数操作将输入转换为一个元组流并且通过调用next函数来对其进行迭代。
这是一种简单并有效的接口，并且允许任意操作进行简单组合，很明显这是一种面向IO场景的产物，那个时候CPU消耗相对而言几乎可以忽略： `首先，对于每一个简单的元组next函数都会调用，即使是中间或者最终的结果，比如，数以百万次，next通常是基于函数指针的虚函数实现，这种调用由于无法发挥现代CPU的分支预测能力相比传统的函数调用更加昂贵`。`第二，这种模型通常会导致很差的代码局部性以及复杂的临时记录开销`。这可以通过一个简单的压缩表扫描来证实。由于必须每次产生一个元组，表操作操作符需要记录当前元组的位置并且在需要下个元组时跳转到对应的解压缩代码地址。
这些问题导致一些现代的系统开始抛弃传统的迭代器模型，其或者再内部通过一次解压缩一批元组，或者再外部通过每次next迭代遍历更多的元组【11】，或者一次产生所有的元组【1】。这种面向块的处理其调用代价相对很低使得相对迭代大量元组而言减少了代价。但是也极大消除了迭代器模型的能力，比如不再具有pipeline数据的能力。Pipeline意味着一个操作对数据无需拷贝或者组装可以将数据传递给其父操作符。比如，selections是一个pipeling操作，并且仅仅对数据做传递。但是更复杂的操作比如join也可以pipelined，至少输入环节。当产生更多的元组时这种简单的pipelining将无法使用，元组只有通过materialization才可以继续呗访问。这种materialization也有一些优势，比如允许向量化操作【2】，但是通常丧失pipelining将会由于其需要消耗更多内存带宽显得不太值得。
本文的一个有趣的观察是：特定实现的程序甚至可以媲美非常高效的向量化系统（表1）。

```c
public abstract class AbstractStep<S, E> implements Step<S, E> {
@Override
    public Traverser.Admin<E> next() {
        if (null != this.nextEnd) {
            try {
                return this.prepareTraversalForNextStep(this.nextEnd);
            } finally {
                this.nextEnd = null;
            }
        } else {
            while (true) {
                if (Thread.interrupted()) throw new TraversalInterruptedException();
                final Traverser.Admin<E> traverser = this.processNextStart();
                if (null != traverser.get() && 0 != traverser.bulk())
                    return this.prepareTraversalForNextStep(traverser);
            }
        }
    }
    @Override
    public boolean hasNext() {
        if (null != this.nextEnd)
            return true;
        else {
            try {
                while (true) {
                    if (Thread.interrupted()) throw new TraversalInterruptedException();
                    this.nextEnd = this.processNextStart();
                    if (null != this.nextEnd.get() && 0 != this.nextEnd.bulk())
                        return true;
                    else
                        this.nextEnd = null;
                }
            } catch (final NoSuchElementException e) {
                return false;
            }
        }
    }
}
```

优化方向集中在：
- 从面向操作转为面向数据，尽量重复利用CPU寄存器的能力，模糊操作之间的边界
- 不再是操作驱动数据，转为数据推动操作，达到更高的代码和数据局部性
- 通过利用优化的LLVM编译框架将查询编译为原生机器码

使用LLVM（low level virtual machine）生成可移植的汇编代码，并使用其自带的JIT编译器直接执行。
- LLVM屏蔽了寄存器分配等细节，简化设计
- 跨平台
- LLVM汇编器是强类型，发现潜在Bug
- 产生极致高效的编译代码
- 快速，只需几ms。c++编译器需要数秒。



复杂操作处理： sort，join 无法在一个function里处理：
- c++ code可能会接管控制流
- 导致代码膨胀
需要多个函数，并保证热点路径不要跨越函数边界，这样代数表达式的pipeline将局限在一个LLVM 代码片段内部。


# [llvm实战](https://llvm.org/docs/tutorial/LangImpl01.html)

```c
static LLVMContext TheContext:  保存LLVM数据结构以及类型信息，比如数据表和类型，作为LLVM函数的参数
static IRBuilder<> Builder(TheContext): 用于生成LLVM指令
static std::unique_ptr<Module> TheModule: 包含一系列方法和全局变量，入口。管理生成的所有IR的内存
static std::map<std::string, Value *> NamedValues: 跟踪当前作用域定义的变量以及LLVM中的含义，保存函数参数
llvm::Value [SSA](https://en.wikipedia.org/wiki/Static_single_assignment_form)
```

  
  
全声明周期代码优化
- link-time 过程间代码优化
- install-time 机器相关优化
- runtime 动态优化
- idle-time 根据end-user收集的数据进行优化

LLVM 代码表示：
- 低级别的语言无关的类型系统
- 类型转换的指令和低级别的地址运算
- 两个低级别异常处理指令
- 低级别的内存模型，管理堆，栈，全局数据，代码内存分布。

LLVM是高级别虚拟机（Small-Talk，Self，JVM,微软的CLI）的补充，区别在于
- LLVM没有类定义，继承、异常处理语义；
- LLVM无法支持u'n一个运行时系统或者对象模型
- LLVM 不保证类型安全，内存安全。

整体流程：
- AST 类
```c
/// FunctionAST - This class represents a function definition itself.
class FunctionAST {
  std::unique_ptr<PrototypeAST> Proto;
  std::unique_ptr<ExprAST> Body;

public:
  FunctionAST(std::unique_ptr<PrototypeAST> Proto,
              std::unique_ptr<ExprAST> Body)
      : Proto(std::move(Proto)), Body(std::move(Body)) {}

  Function *codegen();
};

} // end anonymous namespace
```
- codegen
```c
Function *FunctionAST::codegen() {
  // First, check for an existing function from a previous 'extern' declaration.
  Function *TheFunction = TheModule->getFunction(Proto->getName());

  if (!TheFunction)
    TheFunction = Proto->codegen();

  if (!TheFunction)
    return nullptr;

  // Create a new basic block to start insertion into.
  BasicBlock *BB = BasicBlock::Create(TheContext, "entry", TheFunction);
  Builder.SetInsertPoint(BB);

  // Record the function arguments in the NamedValues map.
  NamedValues.clear();
  for (auto &Arg : TheFunction->args())
    NamedValues[Arg.getName()] = &Arg;

  if (Value *RetVal = Body->codegen()) {
    // Finish off the function.
    Builder.CreateRet(RetVal);

    // Validate the generated code, checking for consistency.
    verifyFunction(*TheFunction);

    return TheFunction;
  }

  // Error reading body, remove function.
  TheFunction->eraseFromParent();
  return nullptr;
}
```
- IR
```c
ready> def bar(a) foo(a, 4.0) + bar(31337);
Read function definition:
define double @bar(double %a) {
entry:
  %calltmp = call double @foo(double %a, double 4.000000e+00)
  %calltmp1 = call double @bar(double 3.133700e+04)
  %addtmp = fadd double %calltmp, %calltmp1
  ret double %addtmp
}
```
- JIT
```c
ready> def foo(x) sin(x)*sin(x) + cos(x)*cos(x);
Read function definition:
define double @foo(double %x) {
entry:
  %calltmp = call double @sin(double %x)
  %multmp = fmul double %calltmp, %calltmp
  %calltmp2 = call double @cos(double %x)
  %multmp4 = fmul double %calltmp2, %calltmp2
  %addtmp = fadd double %multmp, %multmp4
  ret double %addtmp
}

ready> foo(4.0);
Read top-level expression:
define double @3() {
entry:
  %calltmp = call double @foo(double 4.000000e+00)
  ret double %calltmp
}

Evaluated to 1.000000
```
整个LLVM只有31个OpCode。

[SSA](https://en.wikipedia.org/wiki/Static_single_assignment_form)： Static Single Assignment Form
Intermediate representation的特性，每个变量严格分配一次，先定义后使用。IR中已经存在的变量会分裂为多个版本，新变量由原始变量名以及下标组成。所以每个定义都有自己的一个版本。
目标： 解决不同的
Intermediate representation的特性，每个变量严格分配一次，先定义后使用。IR中已经存在的变量会分裂为多个版本，新变量由原始变量名以及下标组成。所以每个定义都有自己的一个版本。


TigerGraph
- 原生分布式存储 计算和存储紧密相连
- 尽量内存缓存，底层紧凑存储并紧凑（2x-10x）加载到内存中，增加内存缓存数据量以及cache命中率。
- 并行执行和共享内容，支持massively parallel processing，多路径并发执行。
- 存储和处理引擎用c++实现
- 自动分区，多节点间，节点内通过hash定位， 哈希打散，O（1） 开销，一个顶点所有的出边都集中在一台server机器上。
- 分布式计算
- 编程抽象： 一种MPP计算模型
- GSQL



